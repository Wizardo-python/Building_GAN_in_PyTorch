{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDJwQPZcupab"
   },
   "source": [
    "# Generative Adversarial Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim\n",
    "\n",
    "To implement and train a simple generative-discriminative network on the MNIST dataset and generate novel images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Building custom dataset and dataloader.\n",
    "* Understand the generator-discriminator network.\n",
    "* Implement training loop for generative adversarial network. (GAN)\n",
    "* Train and evaluate GAN on MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google colab setup\n",
    "Run the following cell to load the \"autoreload\" extension. The \"autoreload\" extension allows us to automatically reload (re-import) Python modules that are imported or defined when they change. This is particularly useful when we actively developing or modifying code in external modules and want those changes to be automatically reflected in the notebook without manually restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd drive/MyDrive/path\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   after running this block you should see files from the folder\n",
    "HOME = os.getcwd()\n",
    "print(os.listdir(HOME))\n",
    "sys.path.append(HOME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtaO2qGf_mdG",
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Generative Adversarial Networks (GANs)\n",
    "\n",
    "### What is a GAN?\n",
    "\n",
    "In 2014, [Goodfellow et al.](https://arxiv.org/abs/1406.2661) presented a method for training generative models called Generative Adversarial Networks (GANs for short). In a GAN, we build two different neural networks. Our first network is a traditional classification network, called the **discriminator**. We will train the discriminator to take images, and classify them as being real (belonging to the training set) or fake (not present in the training set). Our other network, called the **generator**, will take random noise as input and transform it using a neural network to produce images. The goal of the generator is to fool the discriminator into thinking the images it produced are real.\n",
    "\n",
    "We can think of this back and forth process of the generator ($G$) trying to fool the discriminator ($D$), and the discriminator trying to correctly classify real vs. fake as a minimax game:\n",
    "$$\\underset{G}{\\text{minimize}}\\; \\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "where $z \\sim p(z)$ are the random noise samples, $G(z)$ are the generated images using the neural network generator $G$, and $D$ is the output of the discriminator, specifying the probability of an input being real. In [Goodfellow et al.](https://arxiv.org/abs/1406.2661), they analyze this minimax game and show how it relates to minimizing the Jensen-Shannon divergence between the training data distribution and the generated samples from $G$.\n",
    "\n",
    "To optimize this minimax game, we will aternate between taking gradient *descent* steps on the objective for $G$, and gradient *ascent* steps on the objective for $D$:\n",
    "1. update the **generator** ($G$) to minimize the probability of the __discriminator making the correct choice__. \n",
    "2. update the **discriminator** ($D$) to maximize the probability of the __discriminator making the correct choice__.\n",
    "\n",
    "While these updates are useful for analysis, they do not perform well in practice. Instead, we will use a different objective when we update the generator: maximize the probability of the **discriminator making the incorrect choice**. This small change helps to allevaiate problems with the generator gradient vanishing when the discriminator is confident. This is the standard update used in most GAN papers, and was used in the original paper from [Goodfellow et al.](https://arxiv.org/abs/1406.2661). \n",
    "\n",
    "In this project, I will alternate the following updates:\n",
    "1. Update the generator ($G$) to maximize the probability of the discriminator making the incorrect choice on generated data:\n",
    "$$\\underset{G}{\\text{maximize}}\\;  \\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
    "2. Update the discriminator ($D$), to maximize the probability of the discriminator making the correct choice on real and generated data:\n",
    "$$\\underset{D}{\\text{maximize}}\\; \\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] + \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "\n",
    "Since 2014, GANs have exploded into a huge research area, with massive [workshops](https://sites.google.com/site/nips2016adversarial/), and [hundreds of new papers](https://github.com/hindupuravinash/the-gan-zoo). Compared to other approaches for generative models, they often produce the highest quality samples but are some of the most difficult and finicky models to train (see [this github repo](https://github.com/soumith/ganhacks) that contains a set of 17 hacks that are useful for getting models working). Improving the stabiilty and robustness of GAN training is an open research question, with new papers coming out every day! For a more recent tutorial on GANs, see [here](https://arxiv.org/abs/1701.00160). There is also some even more recent exciting work that changes the objective function to Wasserstein distance and yields much more stable results across model architectures: [WGAN](https://arxiv.org/abs/1701.07875), [WGAN-GP](https://arxiv.org/abs/1704.00028).\n",
    "\n",
    "Here I will implement basic vanilla GANs and vanilla GANs with least-squared loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78rH-FoC_mdL",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from torch import nn\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fa68wtAMQJKr"
   },
   "source": [
    " Helper functions to help visualize the MNIST dataset, verify the neural networks implemented, and initialize weights in the `torch.nn` modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzZnoR2pZ5rY"
   },
   "outputs": [],
   "source": [
    "def show_images(images):\n",
    "    images = torch.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
    "    sqrtn = int(math.ceil(math.sqrt(images.shape[0])))\n",
    "    sqrtimg = int(math.ceil(math.sqrt(images.shape[1])))\n",
    "\n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
    "    return \n",
    "\n",
    "def count_params(model):\n",
    "    \"\"\"Count the number of parameters in the model\"\"\"\n",
    "    param_count = sum([p.numel() for p in model.parameters()])\n",
    "    return param_count\n",
    "\n",
    "def initialize_weights(m):\n",
    "  \"\"\" Initializes the weights of a torch.nn model using xavier initialization\"\"\"\n",
    "  if isinstance(m, nn.Linear) or isinstance(m, nn.ConvTranspose2d):\n",
    "    nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "def rel_error(x, y, eps=1e-10):\n",
    "    \"\"\"\n",
    "    Compute the relative error between a pair of tensors x and y,\n",
    "    which is defined as:\n",
    "\n",
    "                            max_i |x_i - y_i]|\n",
    "    rel_error(x, y) = -------------------------------\n",
    "                      max_i |x_i| + max_i |y_i| + eps\n",
    "\n",
    "    Inputs:\n",
    "    - x, y: Tensors of the same shape\n",
    "    - eps: Small positive constant for numeric stability\n",
    "\n",
    "    Returns:\n",
    "    - rel_error: Scalar giving the relative error between x and y\n",
    "    \"\"\"\n",
    "    \"\"\" returns relative error between x and y \"\"\"\n",
    "    top = (x - y).abs().max().item()\n",
    "    bot = (x.abs() + y.abs()).clamp(min=eps).max().item()\n",
    "    return top / bot\n",
    "\n",
    "def reset_seed(number):\n",
    "  \"\"\"\n",
    "  Reset random seed to the specific number\n",
    "\n",
    "  Inputs:\n",
    "  - number: A seed number to use\n",
    "  \"\"\"\n",
    "  random.seed(number)\n",
    "  torch.manual_seed(number)\n",
    "  return\n",
    "\n",
    "dtype = torch.float\n",
    "device = 'cpu'\n",
    "answers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6MV195M_mdR",
    "tags": [
     "pdf-ignore"
    ]
   },
   "source": [
    "## Dataset\n",
    " GANs are notoriously finicky with hyperparameters, and also require many training epochs. In order to make this endevour fruitful, I will be working on the MNIST dataset, which is 60,000 training and 10,000 test images. Each picture contains a centered image of white digit on black background (0 through 9). This was one of the first datasets used to train convolutional neural networks and it is fairly easy -- a standard CNN model can easily exceed 99% accuracy. \n",
    "\n",
    "I will use the PyTorch MNIST wrapper, which downloads and loads the MNIST dataset. See the [documentation](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py) for more information about the interface. The default parameters will take 5,000 of the training examples and place them into a validation dataset. The data will be saved into a folder called `MNIST_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVIGFRTz_mdS",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "NOISE_DIM = 96\n",
    "\n",
    "print('download MNIST if not exist')\n",
    "\n",
    "mnist_train = dset.MNIST('./MNIST_data', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "loader_train = DataLoader(mnist_train, batch_size=batch_size,\n",
    "                          shuffle=True, drop_last=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZvir2Cm_mdV"
   },
   "source": [
    "## Random Noise\n",
    "The first step is to generate uniform noise from -1 to 1 with shape `[batch_size, noise_dim]`\n",
    "\n",
    "Hint is to use `torch.rand`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdUieMiy_mdZ"
   },
   "outputs": [],
   "source": [
    "from gan import sample_noise\n",
    "reset_seed(0)\n",
    "\n",
    "\n",
    "batch_size = 3\n",
    "noise_dim = 4\n",
    "\n",
    "z = sample_noise(batch_size, noise_dim)\n",
    "assert z.shape == (batch_size, noise_dim)\n",
    "assert torch.is_tensor(z)\n",
    "assert torch.all(z >= -1.0) and torch.all(z <= 1.0)\n",
    "assert torch.any(z < 0.0) and torch.any(z > 0.0)\n",
    "print('All tests passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16F3IOHK_mdj"
   },
   "source": [
    "# Discriminator\n",
    "First step is to build a discriminator. All fully connected layers should include bias terms. The architecture is:\n",
    " * Fully connected layer with input size 784 and output size 256\n",
    " * LeakyReLU with alpha 0.01\n",
    " * Fully connected layer with input_size 256 and output size 256\n",
    " * LeakyReLU with alpha 0.01\n",
    " * Fully connected layer with input size 256 and output size 1\n",
    " \n",
    "Leaky ReLU nonlinearity computes $f(x) = \\max(\\alpha x, x)$ for some fixed constant $\\alpha$; for the LeakyReLU nonlinearities in the architecture above I set $\\alpha=0.01$.\n",
    " \n",
    "The output of the discriminator should have shape `[batch_size, 1]`, and contain real numbers corresponding to the scores that each of the `batch_size` inputs is a real image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6O2hnRu9_mdo"
   },
   "source": [
    "Using the `nn.Sequential` for this model definition and all the following models in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0bfhJhp_mdp"
   },
   "outputs": [],
   "source": [
    "from gan import discriminator\n",
    "\n",
    "def test_discriminator(true_count=267009):\n",
    "  model = discriminator()\n",
    "  cur_count = count_params(model)\n",
    "  print(cur_count)\n",
    "  if cur_count != true_count:\n",
    "    print('Incorrect number of parameters in discriminator. Check your achitecture.')\n",
    "  else:\n",
    "    print('Correct number of parameters in discriminator.')     \n",
    "\n",
    "test_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIorZ7EK_mds"
   },
   "source": [
    "# Generator\n",
    "Now to build the generator network:\n",
    " * Fully connected layer from noise_dim to 1024\n",
    " * `ReLU`\n",
    " * Fully connected layer with size 1024 \n",
    " * `ReLU`\n",
    " * Fully connected layer with size 784\n",
    " * `TanH` (to clip the image to be in the range of [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3Og3IjU_mdz"
   },
   "outputs": [],
   "source": [
    "from gan import generator\n",
    "\n",
    "def test_generator(true_count=1858320):\n",
    "  model = generator(4)\n",
    "  cur_count = count_params(model)\n",
    "  print(cur_count)\n",
    "  if cur_count != true_count:\n",
    "    print('Incorrect number of parameters in generator. Check your achitecture.')\n",
    "  else:\n",
    "    print('Correct number of parameters in generator.')\n",
    "\n",
    "test_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayjC9wo8_md1"
   },
   "source": [
    "# GAN Loss\n",
    "\n",
    "Compute the generator and discriminator loss. The generator loss is:\n",
    "$$\\ell_G  =  -\\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
    "and the discriminator loss is:\n",
    "$$ \\ell_D = -\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] - \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "Note that these are negated from the equations presented earlier as we will be *minimizing* these losses.\n",
    "\n",
    "For the purpose of these equations, I assume that the output from the discriminator is a real number in the range $0 < D(x) < 1$ which results from squashing the raw score from the discriminator through a sigmoid function. However for a cleaner and more numerically stable implementation, I have not included the sigmoid in the discriminator architecture above -- instead I will implement the sigmoid as part of the loss function.\n",
    "\n",
    "**HINTS**: To compute these losses in a numerically stable manner the function [`torch.nn.functional.binary_cross_entropy_with_logits`](https://pytorch.org/docs/stable/nn.functional.html#binary-cross-entropy-with-logits) can be used.\n",
    "\n",
    "Given a score $s\\in\\mathbb{R}$ and a label $y\\in\\{0, 1\\}$, the binary cross entropy loss (with logits) is defined as:\n",
    "\n",
    "$$ bce(s, y) = -y * \\log(\\sigma(s)) - (1 - y) * \\log(1 - \\sigma(s)) $$\n",
    "\n",
    "where $\\sigma(s)=1/(1+\\exp(-s))$ is the sigmoid function.\n",
    "\n",
    "A naive implementation of this formula can be numerically unstable, so I prefer to use the built-in PyTorch implementation.\n",
    "\n",
    "We additionally need to compute labels corresponding to real or fake and use the logit arguments to determine their size. So make sure we cast these labels to the correct data type using the global `dtype` variable, for example:\n",
    "\n",
    "`true_labels = torch.ones(size, device=device)`\n",
    "\n",
    "Instead of computing the expectation of $\\log D(G(z))$, $\\log D(x)$ and $\\log \\left(1-D(G(z))\\right)$, we will be averaging over elements of the minibatch, so make sure to combine the loss by averaging instead of summing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNjvlGIP_md8"
   },
   "source": [
    "Typically, errors < `1e-7` are desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcQsiznb_md9"
   },
   "outputs": [],
   "source": [
    "from gan import discriminator_loss\n",
    "\n",
    "answers['logits_fake'] = torch.tensor(\n",
    "  [-1.80865868,  0.09030055, -0.4428902 , -0.07879368, -0.37655044,\n",
    "    0.32084742, -0.28590837,  1.01376281,  0.99241439,  0.39394346],\n",
    "  dtype=dtype, device=device)\n",
    "answers['d_loss_true'] = torch.tensor(1.8423983904443109, dtype=dtype, device=device)\n",
    "answers['logits_real'] = torch.tensor(\n",
    "  [ 0.93487311, -1.01698916, -0.57304769, -0.88162704, -1.40129389,\n",
    "   -1.45395693, -1.54239755, -0.57273325,  0.98584429,  0.13312152],\n",
    "  dtype=dtype, device=device)\n",
    "\n",
    "def test_discriminator_loss(logits_real, logits_fake, d_loss_true):\n",
    "  d_loss = discriminator_loss(logits_real, logits_fake)\n",
    "  print(\"Maximum error in d_loss: %g\"%rel_error(d_loss_true, d_loss))\n",
    "test_discriminator_loss(answers['logits_real'], answers['logits_fake'],\n",
    "                        answers['d_loss_true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_q2hBzD_meA"
   },
   "outputs": [],
   "source": [
    "from gan import generator_loss\n",
    "\n",
    "answers['g_loss_true'] = torch.tensor(0.771286196423346, dtype=dtype, device=device)\n",
    "\n",
    "def test_generator_loss(logits_fake, g_loss_true):\n",
    "  g_loss = generator_loss(logits_fake)\n",
    "  print(\"Maximum error in g_loss: %g\"%rel_error(g_loss_true, g_loss))\n",
    "\n",
    "test_generator_loss(answers['logits_fake'], answers['g_loss_true'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zE1L2nqy_meD"
   },
   "source": [
    "# Optimizing our loss\n",
    "\n",
    "\n",
    "Next, I'll define a function that returns an `optim.Adam` optimizer for the given model with a 1e-3 learning rate, beta1=0.5, beta2=0.999. I'll use this to construct optimizers for the generators and discriminators for the rest of the notebook in `get_optimizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "674H6PyJ_meH"
   },
   "source": [
    "# Training a GAN!\n",
    "\n",
    "To analyze based on outputs and findings we plot loss curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement a single training step for a GAN:\n",
    "1. Sample a batch of real images from the train dataloader, and a batch of fake images from the generator.\n",
    "2. Pass them through the discriminator and calculate the loss over discriminator logits.\n",
    "3. Backpropogate discriminator loss and update discriminator parameters.\n",
    "4. Sample images from generator, pass them through discriminator and get fake images logits.\n",
    "5. Calculate generator loss and backpropogate it. Perform update step for the generator.\n",
    "\n",
    "The key here is to identify the trainable and non-trainable parts of the system when performing each of the above steps. Use `.detach()` wisely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEPATH = \"./\"\n",
    "\n",
    "def run_a_gan(D, G, D_solver, G_solver, discriminator_loss, generator_loss, save_filename=\"images.jpg\", show_every=250, \n",
    "              batch_size=128, noise_size=96, num_epochs=10):\n",
    "  \"\"\"\n",
    "  Train a GAN!\n",
    "  \n",
    "  Inputs:\n",
    "  - D, G: PyTorch models for the discriminator and generator\n",
    "  - D_solver, G_solver: torch.optim Optimizers to use for training the\n",
    "    discriminator and generator.\n",
    "  - discriminator_loss, generator_loss: Functions to use for computing the generator and\n",
    "    discriminator loss, respectively.\n",
    "  - show_every: Show samples after every show_every iterations.\n",
    "  - batch_size: Batch size to use for training.\n",
    "  - noise_size: Dimension of the noise to use as input to the generator.\n",
    "  - num_epochs: Number of epochs over the training dataset to use for training.\n",
    "  \"\"\"\n",
    "  iter_count = 0\n",
    "  for epoch in range(num_epochs):\n",
    "    for x, _ in loader_train:\n",
    "      if len(x) != batch_size:\n",
    "        continue\n",
    "      \n",
    "      d_total_error = None\n",
    "      g_error = None\n",
    "      \n",
    "      fake_images = None\n",
    "      \n",
    "      # x[x <= 0.5] = -1\n",
    "      # x[x > 0.5] = 1\n",
    "      real_data = x * 2 - 1\n",
    "      real_data = real_data.to(device)\n",
    "      real_data = real_data.view(batch_size, -1)\n",
    "\n",
    "      logits_real = D(real_data)\n",
    "\n",
    "      sample_noise_batch = sample_noise(batch_size, noise_size, device=device)\n",
    "      fake_data = G(sample_noise_batch)\n",
    "      logits_fake = D(fake_data)\n",
    "\n",
    "      d_loss = discriminator_loss(logits_real, logits_fake)\n",
    "\n",
    "      D_solver.zero_grad()\n",
    "      d_loss.backward()\n",
    "      D_solver.step()\n",
    "\n",
    "      sample_noise_batch = sample_noise(batch_size, noise_size, device = device)\n",
    "      fake_data = G(sample_noise_batch)\n",
    "      logits_fake = D(fake_data)\n",
    "\n",
    "      g_loss = generator_loss(logits_fake)\n",
    "\n",
    "      G_solver.zero_grad()\n",
    "      g_loss.backward()\n",
    "      G_solver.step()\n",
    "\n",
    "      d_total_error = d_loss\n",
    "      g_error = g_loss\n",
    "      fake_images = fake_data\n",
    "\n",
    "      if (iter_count % show_every == 0):\n",
    "        print('Iter: {}, D: {:.4}, G:{:.4}'.format(iter_count,d_total_error.item(),g_error.item()))\n",
    "        imgs_numpy = fake_images.data.cpu()\n",
    "        show_images(imgs_numpy[0:16])\n",
    "        plt.show()\n",
    "        print()\n",
    "      iter_count += 1\n",
    "    if epoch == num_epochs - 1:\n",
    "      show_images(imgs_numpy[0:16])\n",
    "      plt.savefig(os.path.join(SAVEPATH ,save_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the GAN! The last epoch results will be stored in `fc_gan_results.jpg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan import get_optimizer\n",
    "reset_seed(0)\n",
    "\n",
    "# Make the discriminator\n",
    "D = discriminator().to(device)\n",
    "\n",
    "# Make the generator\n",
    "G = generator().to(device)\n",
    "\n",
    "# Using the written function to get optimizers for the Discriminator and the Generator\n",
    "D_solver = get_optimizer(D)\n",
    "G_solver = get_optimizer(G)\n",
    "run_a_gan(D, G, D_solver, G_solver, discriminator_loss, generator_loss, 'fc_gan_results.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares GAN\n",
    "We'll now look at [Least Squares GAN](https://arxiv.org/abs/1611.04076), a newer, more stable alernative to the original GAN loss function. For this part, all I have to do is change the loss function and retrain the model. I'll implement equation (9) in the paper, with the generator loss:\n",
    "$$\\ell_G  =  \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[\\left(D(G(z))-1\\right)^2\\right]$$\n",
    "\n",
    "and the discriminator loss:\n",
    "\n",
    "$$ \\ell_D = \\frac{1}{2}\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\left(D(x)-1\\right)^2\\right] + \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[ \\left(D(G(z))\\right)^2\\right]$$\n",
    "\n",
    "In these equations, I assume that the output from the discriminator is an unbounded real number $-\\infty < D(x) < \\infty$.\n",
    "\n",
    "\n",
    "**HINTS**: Instead of computing the expectation, I will be averaging over elements of the minibatch, so I combine the loss by averaging instead of summing. When plugging in for $D(x)$ and $D(G(z))$ I use the direct output from the discriminator (`scores_real` and `scores_fake`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan import ls_discriminator_loss\n",
    "from gan import ls_generator_loss\n",
    "\n",
    "answers['d_loss_lsgan_true'] = torch.tensor(1.8770293614440594, dtype=dtype, device=device)\n",
    "answers['g_loss_lsgan_true'] = torch.tensor(0.816954786997558, dtype=dtype, device=device)\n",
    "def test_lsgan_loss(score_real, score_fake, d_loss_true, g_loss_true):\n",
    "  d_loss = ls_discriminator_loss(score_real, score_fake)\n",
    "  g_loss = ls_generator_loss(score_fake)\n",
    "  print(\"Maximum error in d_loss: %g\"%rel_error(d_loss_true, d_loss))\n",
    "  print(\"Maximum error in g_loss: %g\"%rel_error(g_loss_true, g_loss))\n",
    "\n",
    "test_lsgan_loss(answers['logits_real'], answers['logits_fake'],\n",
    "                answers['d_loss_lsgan_true'], answers['g_loss_lsgan_true'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last epoch results will be stored in `ls_gan_results.jpg` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(0)\n",
    "\n",
    "D_LS = discriminator().to(device)\n",
    "G_LS = generator().to(device)\n",
    "\n",
    "D_LS_solver = get_optimizer(D_LS)\n",
    "G_LS_solver = get_optimizer(G_LS)\n",
    "\n",
    "run_a_gan(D_LS, G_LS, D_LS_solver, G_LS_solver, ls_discriminator_loss, ls_generator_loss, 'ls_gan_results.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total1 = (96 * 1024 + 1024) + (1024 * 1024 + 1024) + (1024 * 784 + 784)\n",
    "Total1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total2 = (192 * 1024 + 1024) + (1024 * 1024 + 1024) + (1024 * 784 + 784)\n",
    "Total2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total3 = (256 * 1024 + 1024) + (1024 * 1024 + 1024) + (1024 * 784 + 784)\n",
    "Total3"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "generative_adversarial_networks.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
